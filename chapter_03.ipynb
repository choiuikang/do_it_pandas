{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7423f18a",
   "metadata": {},
   "source": [
    "# 03-1 나만의 데이터 만들기\n",
    "02장에서는 파일에서 데이터 집합을 불러온 다음 실습을 진행했습니다. 이번에는 실습에 사용할 시리즈와 데이터프레임을 직접 만들어서 진행하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de90147f",
   "metadata": {},
   "source": [
    "## 시리즈와 데이터프레임 직접 만들기\n",
    "#### 1. 시리즈 만들기\n",
    "판다스의 Series 메서드에 리스트를 전달하여 시리즈를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c626317e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    banana\n",
      "1        42\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "s=pd.Series(['banana', 42])\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0935eb45",
   "metadata": {},
   "source": [
    "#### 2. 02장에서 인덱스는 보통 0부터 시작한다고 설명했던 것을 기억하나요? 하지만 시리즈를 생성할 때 문자열을 인덱스로 지정할 수도 있습니다. 문자열을 인덱스로 지정하려면 Series 메서드의 index 인자를 통해 인덱스로 사용하고자 하는 문자열을 리스트에 담아 전달하면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1458a443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         Wes Mckinney\n",
      "1    Creator of Pandas\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "s=pd.Series(['Wes Mckinney', 'Creator of Pandas'])\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6f3023b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Person         Wes McKinney\n",
      "Who       Creator of Pandas\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "s = pd.Series(['Wes McKinney','Creator of Pandas'],index=['Person','Who'])\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b2559e",
   "metadata": {},
   "source": [
    "#### 3. 데이터프레임 만들기\n",
    "데이터프레임을 만들기 위해서는 딕셔너리를 DaitaFram클래스에 전달해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bbc67d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                name    Occupation        Died        Born  Age\n",
      "0  Rosaline Franklin       Chemist  1957-04-16  1920-07-25   37\n",
      "1     William Gosset  Statistician  1937-10-16  1876-06-13   61\n"
     ]
    }
   ],
   "source": [
    "scientists= pd.DataFrame({\n",
    "    'name':['Rosaline Franklin','William Gosset'],\n",
    "    'Occupation':['Chemist','Statistician'],\n",
    "    'Died':['1957-04-16','1937-10-16'],\n",
    "    'Born':['1920-07-25','1876-06-13'],\n",
    "    'Age':[37,61]}\n",
    ")\n",
    "print(scientists)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46efd790",
   "metadata": {},
   "source": [
    "#### 4. \n",
    "시리즈와 마찬가지로 데이터프레임도 인덱스를 따로 지정하지 않으면 인덱스를 0부터 자동으로 생성합니다. 인덱스를 따로 지정하려면 index 인자에 리스트를 전달하면 됩니다. 또 columns 인자를 사용하면 데이터프레임의 열 순서를 지정할 수 있습니다. 예를 들어 데이터프레임을 만들 때 Occupation,Born, Died,Age의 순서로 딕셔너리를 전달했어도 columns 인자에 Occupation,Born, Died,Age의 순서로 열 이름을 전달하면 생성된 데이터프레임의 열 순서는 columns에 전달한 값을 따라갑니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "58cdc278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Occupation        Born  Age        Died\n",
      "Rosaline Franklin       Chemist  1920-07-25   37  1957-04-16\n",
      "William Gosset     Statistician  1876-06-13   61  1937-10-16\n"
     ]
    }
   ],
   "source": [
    "scientists=pd.DataFrame(\n",
    "    data={'Occupation':['Chemist','Statistician'],\n",
    "         'Born':['1920-07-25','1876-06-13'],\n",
    "         'Died':['1957-04-16','1937-10-16'],\n",
    "         'Age':[37,61]},\n",
    "    index=['Rosaline Franklin','William Gosset'],\n",
    "    columns=['Occupation','Born','Age','Died']\n",
    ")\n",
    "print(scientists)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade2f5ca",
   "metadata": {},
   "source": [
    "#### 5.\n",
    "과정 1에서 데이터프레임을 만들 대 딕셔너리를 전달한다고 했습니다. 그런데 딕셔너리는 키(Key)와 값(Value)으로 이루어진 한 쌍의 데이터들의 순서는 보장하지 않습니다. 만약 순서가 보장된 딕셔너리를 던달하려면 OrdereDict를 사용해야 합니다. 다음과 같이 입력하면 딕셔너리의 데이터 순서를 그대로 유지하면서 데이터프레임을 만들 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d63f8c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Name    Occupation        Died        Born  Age\n",
      "0  Rosaline Franklin       Chemist  1957-04-16  1920-07-25   37\n",
      "1     William Gosset  Statistician  1937-10-16  1876-06-13   61\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "scientists=pd.DataFrame(OrderedDict([\n",
    "    ('Name',['Rosaline Franklin','William Gosset']),\n",
    "    ('Occupation',['Chemist','Statistician']),\n",
    "    ('Died',['1957-04-16','1937-10-16']),\n",
    "    ('Born',['1920-07-25','1876-06-13']),\n",
    "    ('Age',[37,61])\n",
    "])\n",
    ")\n",
    "print(scientists)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6532b1b",
   "metadata": {},
   "source": [
    "# 03-2 시리즈 다루기 - 기초\n",
    "판다스의 데이터를 구성하는 가장 기본 단위는 시리즈입니다. 이번에는 데이터프레임에서 시리즈를 선택하는 방법에 대해 알아보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bcd97c",
   "metadata": {},
   "source": [
    "## 데이터프레임에서 시리즈 선택하기\n",
    "### 1.\n",
    "먼저 변수 scientists에 데이터프레임을 준비합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fb9c71cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "scientists=pd.DataFrame(\n",
    "    data={'Occupation':['Chemist','Statistician'],\n",
    "         'Born':['1920-07-25','1876-06-13'],\n",
    "         'Died':['1957-04-16','1937-10-16'],\n",
    "         'Age':[37,61]},\n",
    "    index=['Rosaline Franklin','William Gosset'],\n",
    "    columns=['Occupation','Born','Age','Died'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d7ff38",
   "metadata": {},
   "source": [
    "### 2.\n",
    "데이터프레임에서 시리즈를 선택하려면 loc 속성에 인덱스를 전달하면 됩니다. 정말 시리즈를 선택한 것인지 확인하기 위해 type으로 한 번 더 검사합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "48372457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "first_row=scientists.loc['William Gosset']\n",
    "print(type(first_row))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2917011",
   "metadata": {},
   "source": [
    "### 3.\n",
    "first_row 를 출력해 보겠습니다. 여기서 주목해야 할 점은 데이터프레임을 만들 때 Age열에 정수형 리스트를 전달해도 시리즈를 출력해 보면 시리즈의 자료형을 오브젝트로 인식한다는 점입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f19f6006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Occupation    Statistician\n",
      "Born            1876-06-13\n",
      "Age                     61\n",
      "Died            1937-10-16\n",
      "Name: William Gosset, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(first_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac45ccbc",
   "metadata": {},
   "source": [
    "## 시리즈 속성과 메서드 사용하기 - index, values, keys\n",
    "01장에서 실습한 loc,iloc와 같은 속성 외에도 시리즈에는 다양한 속성이 미리 정의되어 있습니다. 이번에는 index, values 속성과 keys메서드에 대해 알아보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67408ea7",
   "metadata": {},
   "source": [
    "### index, values 속성과 keys메서드 사용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b007ae",
   "metadata": {},
   "source": [
    "#### 1.index 속성 사용하기\n",
    "먼저 index 속성을 사용해 보겠습니다. index 속성에는 시리즈의 인덱스가 들어 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "96c479ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Occupation', 'Born', 'Age', 'Died'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(first_row.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa1cc44",
   "metadata": {},
   "source": [
    "#### 2. values 속성 사용하기\n",
    "values 속성에는 시리즈의 데이터가 저장되어 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "26335e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Statistician' '1876-06-13' 61 '1937-10-16']\n"
     ]
    }
   ],
   "source": [
    "print(first_row.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc184c2",
   "metadata": {},
   "source": [
    "#### 3. keys 메서드 사용하기\n",
    "keys는 속성이 아니라 메서드입니다. keys 메서드의 기능은 무엇일까요? keys 메서드는 index속성과 같은 역할을 합니다. 즉, 과정1의 결과와 동일한 결괏값을 얻을 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "22d93e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Occupation', 'Born', 'Age', 'Died'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(first_row.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ef3cee",
   "metadata": {},
   "source": [
    "#### 4. index 속성 응용하기\n",
    "만약 index 속성의 첫 번째 값을 추출하려면 다음과 같이 코드를 작성하면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "00e20487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Occupation\n"
     ]
    }
   ],
   "source": [
    "print(first_row.index[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b754573",
   "metadata": {},
   "source": [
    "#### 5. keys 메서드 응용하기\n",
    "keys 메서드의 결괏값을 이용하여 인덱스의 첫 번째 값을 추출하는 방법은 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bf9ac432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Occupation\n"
     ]
    }
   ],
   "source": [
    "print(first_row.keys()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9589a5fd",
   "metadata": {},
   "source": [
    "## 시리즈의 기초 통계 메서드 사용하기\n",
    "시리즈에는 keys 메서드 외에도 다양한 메서드가 있습니다. 이번에는 시리즈에 미리 정의되어 있는 mean, min, max, std 메서드의 사용 방법을 알아보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6c8196",
   "metadata": {},
   "source": [
    "### 시리즈의 mean, min, max, std 메서드 사용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a945bd",
   "metadata": {},
   "source": [
    "#### 1.\n",
    "이번에는 scientists의 Age 열을 추출해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cf58a1ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rosaline Franklin    37\n",
      "William Gosset       61\n",
      "Name: Age, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "ages = scientists['Age']\n",
    "print(ages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d4f708",
   "metadata": {},
   "source": [
    "#### 2. \n",
    "만약 시리즈를 구성하는 데이터가 정수라면 mean, min, max, std와 같은 통계 메서드를 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cc8ad867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49.0\n"
     ]
    }
   ],
   "source": [
    "print(ages.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "39853ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n"
     ]
    }
   ],
   "source": [
    "print(ages.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "be5e6245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n"
     ]
    }
   ],
   "source": [
    "print(ages.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "61a03361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.97056274847714\n"
     ]
    }
   ],
   "source": [
    "print(ages.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f40e73f",
   "metadata": {},
   "source": [
    "다음은 시리즈에서 자주 사용하는 메서드를 정리한 표입니다. 앞으로 종종 사용할 메서드이므로 한 번 읽어보고 넘어가기 바랍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ceda58c",
   "metadata": {},
   "source": [
    "### 시리즈 메서드 정리\n",
    "시리즈 메서드$\\qquad$$\\qquad$$\\qquad$$\\qquad$설명\n",
    "- append $\\qquad$$\\qquad$$\\qquad$$\\qquad$2개 이상의 시리즈 연결\n",
    "- describe$\\qquad$$\\qquad$$\\qquad$$\\qquad$요약 통계량 계산\n",
    "- drop_duplicates$\\qquad$$\\qquad$$\\quad$중복값이 없는 시리즈 변환\n",
    "- equals$\\qquad$$\\qquad$$\\qquad$$\\qquad$시리즈에 해당 값을 가진 요소가 있는지 확인\n",
    "- get_values$\\qquad$$\\qquad$$\\qquad$$\\quad$시리즈 값 구하기(values 속성과 동일)\n",
    "- isin$\\qquad$$\\qquad$$\\qquad$$\\qquad$$\\quad$시리즈에 포함된 값이 있는지 확인\n",
    "- min$\\qquad$$\\qquad$$\\qquad$$\\qquad$$\\qquad$최소값 반환\n",
    "- max$\\qquad$$\\qquad$$\\qquad$$\\qquad$$\\qquad$최대값 반환\n",
    "- mean$\\qquad$$\\qquad$$\\qquad$$\\qquad$$\\quad$산술 평균 반환\n",
    "- median$\\qquad$$\\qquad$$\\qquad$$\\qquad$$\\quad$중간값 반환\n",
    "- replace$\\qquad$$\\qquad$$\\qquad$$\\qquad$특정 값을 가진 시리즈 값을 교체\n",
    "- sample$\\qquad$$\\qquad$$\\qquad$$\\qquad$시리즈에서 임의의 값을 반환\n",
    "- sort_values$\\qquad$$\\qquad$$\\qquad$$\\qquad$값을 정렬\n",
    "- to_frame$\\qquad$$\\qquad$$\\qquad$$\\qquad$시리즈를 데이터프레임으로 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c378917a",
   "metadata": {},
   "source": [
    "# 03-3 시리즈 다루기 - 응용\n",
    "## 시리즈와 불린 추출\n",
    "02장에서는 원하는 데이터를 추출할 때 특정 인덱스를 지정하여 추출했습니다. 하지만 보통은 추출할 데이터의 정확한 인덱스를 모르는 경우가 더 많죠. 이런 경우에 사용하는 방법은 불린 추출입니다. 불린 추출은 특정 조건을 만족하는 값만 추출할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c25b051",
   "metadata": {},
   "source": [
    "### 시리즈와 불린 추출 사용하기\n",
    "#### 1.\n",
    "이번에는 'scientists.csv'라는 이름의 데이터를 불러옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3db46e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "scientists=pd.read_csv('data/scientists.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c21ab2",
   "metadata": {},
   "source": [
    "#### 2.\n",
    "앞에서 시리즈의 mean, min, max, std 메서드를 호출하여 통계 수치를 계산했던 것을 기억하나요? 통계 수치의 결괏값을 이용하여 불린 추출을 진행해 보겠습니다. 다음은 Age열을 추출하여 max, mean 메서드를 사용한 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7c7b3bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n"
     ]
    }
   ],
   "source": [
    "ages=scientists['Age']\n",
    "print(ages.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "561b47fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59.125\n"
     ]
    }
   ],
   "source": [
    "print(ages.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b7b034",
   "metadata": {},
   "source": [
    "#### 3.\n",
    "이제 불린 추출을 사용할 차례입니다. 예를 들어 평균 나이보다 나이가 많은 사람의 데이터를 추출하려면 어떻게 해야 할까요? 다음 코드를 실행하면 평균 나이보다 나이가 많은 사람의 데이터만 출력됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "29a280f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    61\n",
      "2    90\n",
      "3    66\n",
      "7    77\n",
      "Name: Age, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(ages[ages>ages.mean()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c2e5a3",
   "metadata": {},
   "source": [
    "#### 4.\n",
    "그런데 어떻게 이런일이 가능할가요? ages>ages.mean()의 결과를 출력해 보겠습니다. 그러면 1,2,3,7 인덱스의 데이터가 참이라는 것을 알 수 있습니다. 즉, 조건식을 만족한 값만 출력된 것이죠."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f6153213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    False\n",
      "1     True\n",
      "2     True\n",
      "3     True\n",
      "4    False\n",
      "5    False\n",
      "6    False\n",
      "7     True\n",
      "Name: Age, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print(ages > ages.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a076dc",
   "metadata": {},
   "source": [
    "#### 5.\n",
    "과정 3과 4를 모두 합친 코드는 다음과 같습니다. 즉, 리스트형태로 참이나 거짓을 담아 시리즈에 전달하면 참인 인덱스의 데이터만 추출할 수 있습니다. 바로 이것을 부린 추출이라고 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "264c9d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    37\n",
      "1    61\n",
      "4    56\n",
      "5    45\n",
      "7    77\n",
      "Name: Age, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "manual_bool_values=[True, True, False, False, True, True, False, True]\n",
    "print(ages[manual_bool_values])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138f311c",
   "metadata": {},
   "source": [
    "## 시리즈와 브로드캐스팅\n",
    "그런데 ages>ages.mean()의 결괏값의 개수가 여러 개라는 것이 이상하지 않았나요? 이렇게 시리즈나 데이터프레임에 있는 모든 데이터에 대해 한 번에 연산하는 것을 브로드캐스팅이라고 합니다. 그리고 시리즈처럼 여러 개의 값을 가진 데이터를 벡터라하고 단순 크기를 나타내는 데이터를 스칼라라고 합니다. 앞으로 벡터와 스칼라라는 용어는 자주 사용하므로 기억해 두기 바랍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3400939f",
   "metadata": {},
   "source": [
    "#### 1.\n",
    "다음은 같은 길이의 벡터로 더하기 연산과 곱하기 연산을 수행한 것입니다. 결괏값으로 같은 길이의 벡터가 출력됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4d904390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     74\n",
      "1    122\n",
      "2    180\n",
      "3    132\n",
      "4    112\n",
      "5     90\n",
      "6     82\n",
      "7    154\n",
      "Name: Age, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(ages+ages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "60a1a072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1369\n",
      "1    3721\n",
      "2    8100\n",
      "3    4356\n",
      "4    3136\n",
      "5    2025\n",
      "6    1681\n",
      "7    5929\n",
      "Name: Age, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(ages*ages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bdb6e2",
   "metadata": {},
   "source": [
    "#### 2.\n",
    "만약 벡터에 스칼라를 연산하면 어떻게 될까요? 다음은 벡터의 모든 값에 스칼라를 적용하여 브로드캐스팅한 결과입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "672c8138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    137\n",
      "1    161\n",
      "2    190\n",
      "3    166\n",
      "4    156\n",
      "5    145\n",
      "6    141\n",
      "7    177\n",
      "Name: Age, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(ages+100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4c17f01f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     74\n",
      "1    122\n",
      "2    180\n",
      "3    132\n",
      "4    112\n",
      "5     90\n",
      "6     82\n",
      "7    154\n",
      "Name: Age, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(ages*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d833e9ca",
   "metadata": {},
   "source": [
    "### 3.\n",
    "길이가 서로 다른 벡터를 연산하면 어떻게 될까요? 시리즈와 시리즈를 연산하는 경우 같은 인덱스의 값만 계산합니다. 다음은 데이터의 개수가 2개인 시리즈와 8개인 시리즈를 더한 것입니다. 결괏값을 살펴보면 인덱스가 일치한 0,1만 계산했다는 것을 알 수 있습니다. 나머지 인덱스(2~7)는 계산 할 수 없기 때문에 누락값으로 처리합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b0151e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      1\n",
      "1    100\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(pd.Series([1,100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4e799bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     38.0\n",
      "1    161.0\n",
      "2      NaN\n",
      "3      NaN\n",
      "4      NaN\n",
      "5      NaN\n",
      "6      NaN\n",
      "7      NaN\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(ages+pd.Series([1,100]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aac8d72",
   "metadata": {},
   "source": [
    "#### 4.\n",
    "다음은 sort+index 메서드를 사용한 것입니다. 이때 ascending 인자로 False를 전달하여 인덱스 역순으로 데이터를 정렬했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c08f3f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7    77\n",
      "6    41\n",
      "5    45\n",
      "4    56\n",
      "3    66\n",
      "2    90\n",
      "1    61\n",
      "0    37\n",
      "Name: Age, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "rev_ages=ages.sort_index(ascending=False)\n",
    "print(rev_ages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2333eb",
   "metadata": {},
   "source": [
    "#### 5.\n",
    "그러면 인덱스 순서대로 정렬된 ages와 인덱스 역순으로 정렬된 rev_age를 연산하면 어떻게 될까요? ages의 데이터와 rev_ages의 데이터를 순서대로 더할 것 같지만 그렇지 않습니다. 다음은 ages*2와 ages+rev_ages의 결괏값을 출력한 것입니다. 어떤가요? ages*2와 ages+rev_ages의 결괏값이 동일합니다. ages의 인덱스(0~7)와 rev_ages의 인덱스가 일치하는 값끼리 연산했기 때문이죠. 벡터와 벡터의 연산은 일치하는 인덱스 값끼리 수행한다는 것을 잊지 마세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "eec8f1c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     74\n",
      "1    122\n",
      "2    180\n",
      "3    132\n",
      "4    112\n",
      "5     90\n",
      "6     82\n",
      "7    154\n",
      "Name: Age, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(ages*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "12290af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     74\n",
      "1    122\n",
      "2    180\n",
      "3    132\n",
      "4    112\n",
      "5     90\n",
      "6     82\n",
      "7    154\n",
      "Name: Age, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(ages+rev_ages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8e1029",
   "metadata": {},
   "source": [
    "# 03-4 데이터프레임 다루기\n",
    "데이터프레임도 시리즈와 마찬가지로 불린 추출과 브로드캐스팅을 할 수 있습니다. 그러면 불린 추출부터 실습해 보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c6e2cc",
   "metadata": {},
   "source": [
    "### 불린 추출과 브로드캐스팅\n",
    "#### 1. 불린 추출하기\n",
    "데이터프레임도 불린 추출을 할 수 있습니다. 다음은 데이터프레임의 Age 열에서 Age열의 평균보다 높은 행만 출력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7c70f929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Name        Born        Died  Age     Occupation\n",
      "1        William Gosset  1876-06-13  1937-10-16   61   Statistician\n",
      "2  Florence Nightingale  1820-05-12  1910-08-13   90          Nurse\n",
      "3           Marie Curie  1867-11-07  1934-07-04   66        Chemist\n",
      "7          Johann Gauss  1777-04-30  1855-02-23   77  Mathematician\n"
     ]
    }
   ],
   "source": [
    "print(scientists[scientists['Age']>scientists['Age'].mean()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0582fc3c",
   "metadata": {},
   "source": [
    "#### 2.\n",
    "시리즈에 리스트로 참,거짓을 전달하여 데이터를 추출했던 것을 기억하나요? 참,거짓을 담은 리스트를 bool 벡터라고 부릅니다. 만약 bool 벤터의 길이가 데이터프레임의 행길이보다 짧으면 bool 벡터의 길이만큼만 연산합니다. 다음은 데이터프레임의 loc속성에 길이가 4인 bool벡터를 전달한 것입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8bda5575",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Boolean index has wrong length: 4 instead of 8",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-894b58968834>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscientists\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1102\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_slice_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getbool_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1105\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_list_like_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getbool_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[0;31m# caller is responsible for ensuring non-None axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m         \u001b[0minds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take_with_is_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36mcheck_bool_indexer\u001b[0;34m(index, key)\u001b[0m\n\u001b[1;32m   2280\u001b[0m         \u001b[0;31m# key may contain nan elements, check_array_indexer needs bool array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2281\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2282\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcheck_array_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/indexers.py\u001b[0m in \u001b[0;36mcheck_array_indexer\u001b[0;34m(array, indexer)\u001b[0m\n\u001b[1;32m    483\u001b[0m         \u001b[0;31m# GH26658\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 485\u001b[0;31m             raise IndexError(\n\u001b[0m\u001b[1;32m    486\u001b[0m                 \u001b[0;34mf\"Boolean index has wrong length: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m                 \u001b[0;34mf\"{len(indexer)} instead of {len(array)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: Boolean index has wrong length: 4 instead of 8"
     ]
    }
   ],
   "source": [
    "print(scientists.loc[[True, True, False, True]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e2aefc",
   "metadata": {},
   "source": [
    "#### 3.\n",
    "데이터프레임에 스칼라 연산을 적용하면 어떻게 될까요? 앞에서 시리즈에 스칼라 연산을 적용할 때는 모든 요소에 스칼라를 적용하여 연산했습니다. 데이터프레임도 마찬가지입니다. scientists 데이터프레임에 2를 곱하면 정수 데이터는 2를 곱한 숫자가 되고 문자열 데이터는 문자열이 2배로 늘어납니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c5edc61f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       Name                  Born  \\\n",
      "0        Rosaline FranklinRosaline Franklin  1920-07-251920-07-25   \n",
      "1              William GossetWilliam Gosset  1876-06-131876-06-13   \n",
      "2  Florence NightingaleFlorence Nightingale  1820-05-121820-05-12   \n",
      "3                    Marie CurieMarie Curie  1867-11-071867-11-07   \n",
      "4                Rachel CarsonRachel Carson  1907-05-271907-05-27   \n",
      "5                        John SnowJohn Snow  1813-03-151813-03-15   \n",
      "6                    Alan TuringAlan Turing  1912-06-231912-06-23   \n",
      "7                  Johann GaussJohann Gauss  1777-04-301777-04-30   \n",
      "\n",
      "                   Died  Age                            Occupation  \n",
      "0  1958-04-161958-04-16   74                        ChemistChemist  \n",
      "1  1937-10-161937-10-16  122              StatisticianStatistician  \n",
      "2  1910-08-131910-08-13  180                            NurseNurse  \n",
      "3  1934-07-041934-07-04  132                        ChemistChemist  \n",
      "4  1964-04-141964-04-14  112                    BiologistBiologist  \n",
      "5  1858-06-161858-06-16   90                    PhysicianPhysician  \n",
      "6  1954-06-071954-06-07   82  Computer ScientistComputer Scientist  \n",
      "7  1855-02-231855-02-23  154            MathematicianMathematician  \n"
     ]
    }
   ],
   "source": [
    "print(scientists*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad270adf",
   "metadata": {},
   "source": [
    "# 03-5 시리즈와 데이터프레임의 데이터 처리하기\n",
    "지금까지는 시리즈와 데이터프레임에서 데이터를 추출하는 여러 방법에 대해 알아보았습니다. 이번에는 시리즈와 데이터프레임에 있는 데이터를 처리하는 방법에 대해 알아보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f816c038",
   "metadata": {},
   "source": [
    "### 시리즈와 데이터 프레임의 데이터 처리하기\n",
    "#### 1. 열의 자료형 바꾸기와 새로운 열 추가하기\n",
    "scientists 데이터프레임의 Born과 Died 열의 자료형을 확인해 보겠습니다. 각각의 자료형은 문자열입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "40c34450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n"
     ]
    }
   ],
   "source": [
    "print(scientists['Born'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9214750b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n"
     ]
    }
   ],
   "source": [
    "print(scientists['Died'].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9d20b5",
   "metadata": {},
   "source": [
    "#### 2.\n",
    "날짜를 문자열로 저장한 데이터는 시간 관련 작업을 할 수 있도록 datetime 자료형으로 바꾸는 것이 더 좋습니다. 다음은 Born과 Died 열의 자료형을 datetime이라는 자료형으로 바꾼 다음 format 속성을 '%Y-%m-%d'로 지정하여 날짜 형식을 지정한 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4a36241c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   1920-07-25\n",
      "1   1876-06-13\n",
      "2   1820-05-12\n",
      "3   1867-11-07\n",
      "4   1907-05-27\n",
      "5   1813-03-15\n",
      "6   1912-06-23\n",
      "7   1777-04-30\n",
      "Name: Born, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "born_datetime=pd.to_datetime(scientists['Born'],format='%Y-%m-%d')\n",
    "print(born_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "07caea84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   1958-04-16\n",
      "1   1937-10-16\n",
      "2   1910-08-13\n",
      "3   1934-07-04\n",
      "4   1964-04-14\n",
      "5   1858-06-16\n",
      "6   1954-06-07\n",
      "7   1855-02-23\n",
      "Name: Died, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "died_datetime=pd.to_datetime(scientists['Died'],format='%Y-%m-%d')\n",
    "print(died_datetime)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcae125",
   "metadata": {},
   "source": [
    "#### 3.\n",
    "과정 2에서 각 데이터의 자료형을 datetime 으로 바꿔 born_datetime, died_datetime에 저장했으니 이제 데이터프레임에 각각의 값을 새로운 열로 추가해 보겠습니다. 다음은 scientists 데이터프레임에 born_dt, dide_dt열을 추가한 것입니다. shape 속성으로 데이터프레임의 형태를 살펴보면(8,5)에서 (8,7)로 2개의 열이 추가되었다는 것을 알 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fa942775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Name        Born        Died  Age    Occupation    born_dt  \\\n",
      "0     Rosaline Franklin  1920-07-25  1958-04-16   37       Chemist 1920-07-25   \n",
      "1        William Gosset  1876-06-13  1937-10-16   61  Statistician 1876-06-13   \n",
      "2  Florence Nightingale  1820-05-12  1910-08-13   90         Nurse 1820-05-12   \n",
      "3           Marie Curie  1867-11-07  1934-07-04   66       Chemist 1867-11-07   \n",
      "4         Rachel Carson  1907-05-27  1964-04-14   56     Biologist 1907-05-27   \n",
      "\n",
      "     died_dt  \n",
      "0 1958-04-16  \n",
      "1 1937-10-16  \n",
      "2 1910-08-13  \n",
      "3 1934-07-04  \n",
      "4 1964-04-14  \n"
     ]
    }
   ],
   "source": [
    "scientists['born_dt'],scientists['died_dt']=(born_datetime, died_datetime)\n",
    "print(scientists.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "111065d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 7)\n"
     ]
    }
   ],
   "source": [
    "print(scientists.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da64993",
   "metadata": {},
   "source": [
    "#### 4.\n",
    "이제 시간 계산을 해볼까요? died_dt 열에서 born_dt를 빼면 과학자가 얼마 동안 세상을 살다가 떠낫는지 계산할 수 있습니다. 만약 결괏값이 제대로 출력되지 않는다면 과정 1~3을 다시 실행해 보세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cad5c465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Name        Born        Died  Age          Occupation  \\\n",
      "0     Rosaline Franklin  1920-07-25  1958-04-16   37             Chemist   \n",
      "1        William Gosset  1876-06-13  1937-10-16   61        Statistician   \n",
      "2  Florence Nightingale  1820-05-12  1910-08-13   90               Nurse   \n",
      "3           Marie Curie  1867-11-07  1934-07-04   66             Chemist   \n",
      "4         Rachel Carson  1907-05-27  1964-04-14   56           Biologist   \n",
      "5             John Snow  1813-03-15  1858-06-16   45           Physician   \n",
      "6           Alan Turing  1912-06-23  1954-06-07   41  Computer Scientist   \n",
      "7          Johann Gauss  1777-04-30  1855-02-23   77       Mathematician   \n",
      "\n",
      "     born_dt    died_dt age_days_dt  \n",
      "0 1920-07-25 1958-04-16  13779 days  \n",
      "1 1876-06-13 1937-10-16  22404 days  \n",
      "2 1820-05-12 1910-08-13  32964 days  \n",
      "3 1867-11-07 1934-07-04  24345 days  \n",
      "4 1907-05-27 1964-04-14  20777 days  \n",
      "5 1813-03-15 1858-06-16  16529 days  \n",
      "6 1912-06-23 1954-06-07  15324 days  \n",
      "7 1777-04-30 1855-02-23  28422 days  \n"
     ]
    }
   ],
   "source": [
    "scientists['age_days_dt']=(scientists['died_dt'] - scientists['born_dt'])\n",
    "print(scientists)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32087f0c",
   "metadata": {},
   "source": [
    "#### 5. 시리즈, 데이터프레임의 데이터 섞기\n",
    "가끔은 데이터를 적당히 섞어야 하는 경우도 있습니다. 판다스는 시리즈나 데이터프레임의 데이터를 무작위로 섞어볼 수도 있습니다. 먼저 Age 값을 출력하여 살펴보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9d8beab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    37\n",
      "1    61\n",
      "2    90\n",
      "3    66\n",
      "4    56\n",
      "5    45\n",
      "6    41\n",
      "7    77\n",
      "Name: Age, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(scientists['Age'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ddadfb",
   "metadata": {},
   "source": [
    "#### 6.\n",
    "Age 열의 데이터를 섞으려면 random 라이브러리를 불러와야 합니다. random 라이브러리에는 데이터를 섞어주는 shuffle 메서드가 있습니다. shuffle 메서드에 Age열을 전달하여 데이터를 섞어보겠습니다. Age 열을 출력해 보면 인덱스 0~7에 해당하는 값이 잘섞여 있음을 알 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b7122a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    66\n",
      "1    56\n",
      "2    41\n",
      "3    77\n",
      "4    90\n",
      "5    45\n",
      "6    37\n",
      "7    61\n",
      "Name: Age, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmlrkd67/anaconda3/lib/python3.8/random.py:307: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x[i], x[j] = x[j], x[i]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "random.shuffle(scientists['Age'])\n",
    "print(scientists['Age'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a28c12",
   "metadata": {},
   "source": [
    "#### 7.\n",
    "때로는 열을 통째로 삭제해야 하는 경우도 있습니다. 먼저 scientists 데이터프레임의 열을 확인해 보겠습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "902f8767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Name', 'Born', 'Died', 'Age', 'Occupation', 'born_dt', 'died_dt',\n",
      "       'age_days_dt'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(scientists.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f1b808",
   "metadata": {},
   "source": [
    "#### 8.\n",
    "데이터프레임에서 열을 삭제하려면 데이터프레임의 drop 메서드를 사용해야 합니다. shuffle 메서드로 섞은 Age 열을 삭제해 보겠습니다. drop 메서드의 첫 번째 인자에 열 이름을 리스트에 담아 전달하고 두 번째 인자에는 axis=1을 전달하면 Age열을 삭제할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2e8e04c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Name', 'Born', 'Died', 'Occupation', 'born_dt', 'died_dt',\n",
      "       'age_days_dt'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "scientists_dropped=scientists.drop(['Age'],axis=1)\n",
    "print(scientists_dropped.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d1d936",
   "metadata": {},
   "source": [
    "# 03-6 데이터 저장하고 불러오기\n",
    "지금까지 데이터를 추출하고 처리하는 방법에 대해 알아보았습니다. 일종의 '데이터 가공처리'를 거친 것이죠. 이렇게 잘 가공한 데이터는 안전하게 보관해야 다음에 또 사용할 수 있습니다. 판다스는 데이터를 저장하는 다양한 방법을 제공합니다. 여기서는 가공한 데이터를 피클, CSV,TSV 파일로 저장하고 다시 불러오는 방법에 대해 살펴보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042b8a8b",
   "metadata": {},
   "source": [
    "### 데이터를 피클, CSV, TSV 파일로 저장하고 불러오기\n",
    "#### 1. 피클로 저장하기\n",
    "피클은 데이터를 바이너리 형태로 직렬화한 오브젝트를 저장하는 방법입니다. 피클로 저장하면 스프레드시트보다 더 작은 용량으로 데이터를 저장할 수 있어 매우 편리합니다. 시리즈를 피클로 저장하려면 to_pickle 메서드를 사용하면 되는데, 이때 저장 경로를 문자열로 전달해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e6854eeb",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../output/scientists_names_series.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-99-d72aa79ec83b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscientists\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../output/scientists_names_series.pickle'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_pickle\u001b[0;34m(self, path, compression, protocol, storage_options)\u001b[0m\n\u001b[1;32m   2862\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpickle\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2864\u001b[0;31m         to_pickle(\n\u001b[0m\u001b[1;32m   2865\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2866\u001b[0m             \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mto_pickle\u001b[0;34m(obj, filepath_or_buffer, compression, protocol, storage_options)\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHIGHEST_PROTOCOL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     with get_handle(\n\u001b[0m\u001b[1;32m     91\u001b[0m         \u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    649\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../output/scientists_names_series.pickle'"
     ]
    }
   ],
   "source": [
    "names=scientists['Name']\n",
    "names.to_pickle('../output/scientists_names_series.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0a8031",
   "metadata": {},
   "source": [
    "#### 2. \n",
    "데이터프레임도 피클로 저장할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "251a6bf5",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../output/scientists_df.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-f14e2108dcae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscientists\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../output/scientists_df.pickle'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_pickle\u001b[0;34m(self, path, compression, protocol, storage_options)\u001b[0m\n\u001b[1;32m   2862\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpickle\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2864\u001b[0;31m         to_pickle(\n\u001b[0m\u001b[1;32m   2865\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2866\u001b[0m             \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mto_pickle\u001b[0;34m(obj, filepath_or_buffer, compression, protocol, storage_options)\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHIGHEST_PROTOCOL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     with get_handle(\n\u001b[0m\u001b[1;32m     91\u001b[0m         \u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    649\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../output/scientists_df.pickle'"
     ]
    }
   ],
   "source": [
    "scientists.to_pickle('../output/scientists_df.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9826b8af",
   "metadata": {},
   "source": [
    "#### 3.\n",
    "피클은 바이너리 형태의 오브젝트이기 때문에 저장된 피클 데이터를 편집기와 같은 프로그램으로 열어보면 이상한 문자가 나타납니다. 피클 데이터는 반드시 read_pickle 메서드로 읽어 들여야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a826cfd0",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../output/scientists_names_series.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-9d4531dd44a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscientist_names_form_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../output/scientists_names_series.pickle'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscientist_names_from_pickle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \"\"\"\n\u001b[1;32m    184\u001b[0m     \u001b[0mexcs_to_catch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mAttributeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModuleNotFoundError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m     with get_handle(\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    649\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../output/scientists_names_series.pickle'"
     ]
    }
   ],
   "source": [
    "scientist_names_form_pickle=pd.read_pickle('../output/scientists_names_series.pickle')\n",
    "print(scientist_names_from_pickle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba8a701",
   "metadata": {},
   "source": [
    "#### 4.CSV 파일과 TSV 파일로 저장하기\n",
    "CSV 파일은 데이터를 쉽표로 구분하여 저장한 파일이고 TSV 파일은 데이터를 탭으로 구분하여 저장한 파일입니다. 실제로 각각의 파일을 텍스트 편집기로 열어 살펴보면 데이터가 쉽표, 탭으로 구분되어 있는 것을 알 수 있습니다. 다음은 data 폴더의 'concat_1.csv'파일과 'gapminder.tsv'파일을 비주얼 스튜디오 코드라는 텍스트 편집기로 열어 살펴본것입니다. 비주얼 스튜디오 코드가 없다면 여러분의 컴퓨터에 설치된 텍스트 편집기로 파일을 열어보세요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff983398",
   "metadata": {},
   "source": [
    "#### 5.\n",
    "to_csv 메서드로 시리즈와 데이터프레임을 CSV 파일로 저장할 수 있습니다. 이때 sep 인자를 추가하여 '\\t'를 지정하고 파일의 확장자를 '.tsv'로 지정하면 TSV 파일로 저장할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2f82db3d",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-100-ecb8b07e23af>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-100-ecb8b07e23af>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    scientists.to_csv(''../output/scientists_df.tsv',sep-'\\t')\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "names.to_csv('../output/scientist_names_series.csv')\n",
    "scientists.to_csv(''../output/scientists_df.tsv',sep-'\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618616a8",
   "metadata": {},
   "source": [
    "## 마무리하며\n",
    "이 장에서는 시리즈와 데이터프레임을 좀 더 자세히 다루어 보았습니다. 다음 장부터는 파이썬과 판다스로 그래프를 그리기 위한 기초 개념을 살펴봅니다. 데이터 분석에서 가장 중요한 요소 중 하나인 데이터 시각화에 대한 내용이 시작되는 것이죠. 만약 02,03장을 완벽하게 이해하지 못했다면 다시 공부하고 04장을 시작하세요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d34957",
   "metadata": {},
   "source": [
    "출처 : \"do it 데이터 분석을 위한 판다스 입문\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
